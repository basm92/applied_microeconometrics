---
title: "Applied Microeconometrics - Assignment 1"
author: "Walter Verwer & Bas Machielsen"
date: "8/31/2021"
output:
  pdf_document:
    includes:
      in_header: preamble.tex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse); library(plm); library(stargazer)

dataset <- readr::read_csv("datadynpan2021.csv")
```

1. Explain why first differencing the equation does not solve the endogeneity problem of lagged consumption.

The first difference specification is: 

\begin{align*}
(\log C_{it} - \log C_{it-1}) = \beta_1 \cdot (\log p_{it} - \log p_{it-1}) + \beta_2 \cdot (\log inc_{it} - \log inc_{it-1}) + \\
\beta_3 \cdot (\log ilop_{it} - \log ilop_{it-1}) + \beta_4 + \beta_5 \cdot (\log C_{it-1} - \log C_{it-2}) + u_{it} - u_{it-1}
\end{align*}

First difference estimation is just OLS estimation with transformed data. For the OLS estimator (in general) to be consistent and unbiased, we need $\text{Cov}(X, U)=0$, where $X$ is the matrix containing all regressors. In the context of our transformed data, we need $\text{Cov}(\Delta X, \Delta U)=0$. One of the variables in $\Delta X$ is $\Delta \log C_{it-1}$. If we evaluate the covariance between $\Delta \log C_{it-1}$ and $\Delta U_{it}$, we find that:

\begin{align*}
&\text{Cov}(\Delta \log C_{it-1}, \Delta U_{it}) = \\
&\text{Cov}(\beta \Delta X_{it-1} + \beta_5 \Delta \log C_{it-2} + \Delta u_{it-1}, \Delta u_{it}) = \\
&\text{Cov}(\Delta U_{it-1}, \Delta U_{it}) \neq 0
\end{align*}

Since we observe that the exogeneity assumption is violated, we can conclude that first differencing the equation does not solve the endogeneity problem of lagged consumption.

2. Anderson & Hsiao propose a specific instrumental variable procedure for the model. Write down and perform the associated first stage regression. Comment on its outcomes.

We have to keep in mind that the first-stage regression contains all the exogenous regressors $X$ from the second stage regression, plus the instrument, $C_{it-2}$. Hence, the first-stage model is: 

\begin{align*}
\widehat{\log C_{it-1} - \log C_{it-2}} = \beta_1 \cdot (\log p_{it} - \log p_{it-1}) + \beta_2 \cdot (\log inc_{it} - \log inc_{it-1}) + \\
\beta_3 \cdot (\log ilop_{it} - \log ilop_{it-1}) + \beta_4 + \beta_5 \cdot (\log C_{it-2}) + u_{it-1} - u_{it-2}
\end{align*}

And the predicted values are to be used as follows in the second-stage regression:

<!---
Walter: moet het niet \log C_it-1 - \log C_it-2 zijn ipv zonder log?
-->

\begin{align*}
(\log C_{it} - \log C_{it-1}) = \beta_1 \cdot (\log p_{it} - \log p_{it-1}) + \beta_2 \cdot (\log inc_{it} - \log inc_{it-1}) + \\
\beta_3 \cdot (\log ilop_{it} - \log ilop_{it-1}) + \beta_4 + \beta_5 \cdot \widehat{(C_{it-1} - C_{it-2})} + u_{it} - u_{it-1}
\end{align*}

Using the data, we find the following first-stage regression (table \ref{tab:reg}):

```{r results='asis'}
## Create the first and second differences
dataset <- dataset %>%
    group_by(region) %>%
    mutate(across(contains("log"),
                  ~ .x - dplyr::lag(.x), .names = "l1_{.col}"),
           across(starts_with("log"),
                  ~ dplyr::lag(.x) - dplyr::lag(.x, 2), .names = "l2_{.col}"),
           level_quantity = dplyr::lag(logquantity, 2))

## Run the first-stage regression
first_stage_reg <- lm(formula = "l2_logquantity ~ l1_logprice + l1_logincome + l1_logillegal +
   level_quantity",
   data = dataset)

```

Whereas the F-statistic is acceptable (higher than 10), it is not _much_ higher than 10, leaving questions about the relevance of the instrument. Indeed, the instrument seems to be lacking statistical relevance, and thus predictive power. The coefficient on level quantity is only `r first_stage_reg$coefficients[5]` and insignificant at the 10% level. This means that consumption is $C_{it-2}$ does not predict differences $C_{it-1} - C_{it-2}$ well, meaning there is no clear relationship between absolute consumption and (near-)future increases/decreases of consumption. 

3. Estimate the specification above using the Anderson & Hsiao approach. Comment on the underlying assumptions, tabulate the results and comment on the outcomes.

```{r results='asis'}
# Use a package to estimate Anderson-Hsiao
dataset2 <- plm::pdata.frame(dataset, c("region", "year"))

anderson_hsiao <- plm(l1_logquantity ~ l1_logprice + l1_logincome + 
                          l1_logillegal + l2_logquantity | 
                          l1_logprice + l1_logincome + l1_logillegal + 
                          level_quantity,
                      data=dataset2,
                      model="pooling"
          )

# Compare with Manual 2SLS
dataset <- modelr::add_predictions(dataset, first_stage_reg) %>%
       rename("c_instrumented"=pred) 

manual_2sls <- lm(data=dataset, 
   formula = l1_logquantity ~ l1_logprice + l1_logincome + l1_logillegal + c_instrumented) 

stargazer(first_stage_reg, anderson_hsiao, manual_2sls, 
          label = "tab:reg", header=FALSE, model.names = FALSE,
          column.sep.width="-5pt",
          dep.var.labels=c("$C_{it-1} - C_{it-2}$", 
                           "$C_{it} - C_{it-1}$",
                           "$C_{it} - C_{it-1}$"),
          column.labels = c("First-Stage", "A-H", "Manual 2SLS"),
              omit.stat = c("ll", "ser", "rsq"))
```

The table is displayed below. The estimates from models (2) and (3) in tabel \ref{tab:reg} are the same. Only the variance of the 2SLS-estimator is off. 

<!---
Walter: misschien moeten we SEs clusteren per groep?
-->

4. Describe the Arellano & Bond GMM estimator for this model.

In general the Arellano & Bond GMM estimator aims to use lagged values of endogenous regressors as an instrument. All possible moment conditions are for $t=2,\dots,T$ and $k=2,\dots,t$, applied to the current model given by:

\begin{equation*}
\mathbb{E}[\log(C_{it-k})(u_{it}-u_{it-1})]
\end{equation*}

5. Estimate the model parameters using the Arellano & Bond estimator, tabulate the results and discuss the parameter estimates.

```{r results='asis', warning=FALSE}
# Here, we use the _normal_ specification as default and not the first difference:
# The package will transform the data accordingly
arellano_bond <- pgmm(data = dataset2,
                          logquantity ~ logincome + logprice + 
                            logillegal + lag(logquantity, 1)
                          | lag(logquantity, 2:99), transformation = 'd')

stargazer(arellano_bond, label = "tab:reg_ab", header=FALSE, model.names = FALSE,
          column.sep.width="-5pt",
          column.labels = c('Arellano & Bond'),
              omit.stat = c("ll", "ser", "rsq"))
```

6. What is in your estimate for the short-run and the long-run price elasticity of opium?

7. Now estimate the model parameters using the system estimator (Blundell & Bond). Tabulate results, compute the elasticities (as in 6.).

```{r results='asis', warning = FALSE}
blundell_bond <- pgmm(data = dataset2,
                          logquantity ~ logincome + logprice + 
                            logillegal + lag(logquantity, 1) | 
                            lag(logquantity, 2:99) + lag(l1_logquantity, 2:99))

stargazer(blundell_bond, label = "tab:reg_bb", header=FALSE, model.names = FALSE,
          column.sep.width="-5pt",
          column.labels = c('Blundell & Bond'),
              omit.stat = c("ll", "ser", "rsq"))
```

8. Which parameter estimates do you prefer? Explain why. Are there remaining problems with your preferred estimates?
