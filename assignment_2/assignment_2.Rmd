---
title: "Applied Microeconometrics - Assignment 2"
author: "Walter Verwer (589962) & Bas Machielsen (590049)"
date: \today
output:
  pdf_document:
    includes:
      in_header: preamble.tex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse); library(plm); library(stargazer); library(modelsummary)

dataset <- foreign::read.dta("./searchperiod.dta") 
```

1. Compute the average probability to receive benefits 10 and 30 weeks after application for applicants that had a search period and applicants that did not have a search period.

```{r}
dataset %>%
    group_by(searchperiod) %>%
    summarize(prob_10weeks = mean(benefits_week10), prob_30weeks = mean(benefits_week30)) %>%
    knitr::kable()
```

It seems that there is a large difference in unconditional means in the outcome variable among treated and controlled groups. Individuals exposed to the treatment (a search period) have much lower probabilities of ultimately receiving benefits, whether this is after 10 weeks, or after 30 weeks. This could be a potential indication of the presence of a treatment effect, but a more rigorous examination should ensue. 

2. Make a balancing table in which you compare characteristics of applicants with and without a search period.

```{r results='asis', warning = FALSE}
modelsummary::datasummary_balance(~ searchperiod,
                                  data = dataset %>%
                                      select(c(1,4:23)) %>%
                                      mutate(searchperiod = if_else(
                                          searchperiod == 1,
                                          "With Search", 
                                          "Without Search")) %>%
                                      rename_with(.fn = ~ stringr::str_replace(.x, "_", "")),
                                  output = "latex", 
                                  fmt = "%.3f",
                                  dinm = TRUE,
                                  dinm_statistic = "p.value"
                                    ) %>%
    kableExtra::kable_styling(font_size = 10)

```

It seems that all covariates are rather balanced, indicated by the absence of significant differences in means among the treated and the control group. Of course, because we are dealing with a large number of joint null-hypotheses, we should only reject the null hypothesis according to a Bonferroni-corrected p-value. If our regular p-value criterion would be $p < 0.05$, in this case, we reject the null hypothesis when $p < \frac{0.05}{20} = 0.0025$. Even with this criterion, most of the location dummies are still significantly different in treatment and control groups, indicating that perhaps the treatment was administered in different regions, but was stratified according to all other observables. Adding region-specific fixed effects to the regression specifications should solve this problem. Another variable that differs significantly is age. We observe that older individuals are assigned to the no search group more often than younger individuals.

3. Regress the outcome variables first only on whether or not a search period was applied (which should give the difference-in-means estimate) and next include other covariates in the regression.

```{r}
model1 <- lm(data = dataset, formula = benefits_week10 ~ searchperiod)
model2 <- lm(data = dataset, formula = benefits_week30 ~ searchperiod)
model3 <- update(model1, . ~ . + period1 + period2 + period3 + period4 + 
                     location1 + location2 + location3 + location4)
model4 <- update(model2, . ~ . + period1 + period2 + period3 + period4 + 
                     location1 + location2 + location3 + location4)
model5 <- update(model3, . ~ . + sumincome_12monthsbefore + 
                     sumincome_24monthsbefore + age + female + children + 
                     partner + educ_bachelormaster + educ_prepvocational + 
                     educ_primaryorless + educ_unknown + educ_vocational)
model6 <- update(model4, . ~ . + sumincome_12monthsbefore + 
                     sumincome_24monthsbefore + age + female + children + 
                     partner + educ_bachelormaster + educ_prepvocational +
                     educ_primaryorless + educ_unknown + educ_vocational)

models <- list(model1, model2, model3, model4, model5, model6)
```


```{r, results='asis'}
stargazer(models, title = "Estimations of the Effect of Search on P(Benefits)",
          label = "tab:reg", header=FALSE, model.names = FALSE,
          column.sep.width="0pt", font.size = "footnotesize",
          df=F,
          dep.var.labels = c(rep("Benefits",6)),
          column.labels= c(rep(c("10 Weeks", "30 Weeks"),3)),
          omit = c("period1", "period2", "period3", "period4","location"),
          add.lines = list(c("Period Dummies", rep("No", 2), rep("Yes", 4)),
                            c("Region Dummies", rep("No", 2), rep("Yes", 4))),
          omit.stat = c("ll", "ser", "rsq"))

```

The results imply that the treatment is effective in reducing the probability of receiving benefits on the long-term (30 weeks) by 10-percentage points, and slightly higher (15 percentage points) on the short-term (10-weeks). If there is no selection on unobservables, these estimates give a good estimate of the ATE. But to what extent can these estimates be trusted? 

4. Compute the no-assumption bounds for the treatment effects.

```{r}
# Implement the no assumption bounds
no_assumption_bounds <- function(dataset, y_min, y_max, treatmentvar, depvar){
  depvar <- dplyr::enquo(depvar)
  treatmentvar <- dplyr::enquo(treatmentvar)
  
  pr_treated <- dataset %>%
    summarize(mean = mean(UQ(treatmentvar), na.rm = TRUE)) %>%
    pull() 
  
  pr_untreated <- 1-pr_treated
  
  expected_y_given_deq1 <- dataset %>%
    dplyr::filter(UQ(treatmentvar) == 1) %>%
             summarize(mean = mean(UQ(depvar), na.rm = TRUE)) %>%
             pull()
  
  expected_y_given_deq0 <- dataset%>%
    dplyr::filter(UQ(treatmentvar) == 0) %>%
             summarize(mean = mean(UQ(depvar), na.rm = TRUE)) %>%
             pull()
           
  # bounds on y^*_1: 
  lower_bound_y1 <- expected_y_given_deq1 * pr_treated + y_min * pr_untreated 
  upper_bound_y1 <- expected_y_given_deq1 * pr_treated + y_max * pr_untreated
  
  # bounds on y^*_0:
  lower_bound_y0 <- expected_y_given_deq0 * pr_untreated + y_min * pr_treated 
  upper_bound_y0 <- expected_y_given_deq0 * pr_untreated + y_max * pr_treated
  
  # bounds on the ATE:
  lower_bound_ate <- expected_y_given_deq1*pr_treated - expected_y_given_deq0*pr_untreated + 
    (y_min + y_max)*pr_untreated - y_max 
  upper_bound_ate <- expected_y_given_deq1*pr_treated - expected_y_given_deq0*pr_untreated + 
    (y_min + y_max)*pr_untreated - y_min
  
  out <- tribble(~"lower_bound_y1", ~"upper_bound_y1", ~"lower_bound_y0",
                 ~"upper_bound_y0", ~"lower_bound_ate", ~"upper_bound_ate",
          lower_bound_y1, upper_bound_y1, lower_bound_y0, upper_bound_y0, lower_bound_ate, upper_bound_ate)
  
  return(out)
}
```

```{r}
no_assumption_bounds(dataset, 0,1,searchperiod, benefits_week10) %>%
  knitr::kable(booktabs=T) %>%
    kableExtra::kable_styling(font_size = 7, latex_options = "hold_position")

no_assumption_bounds(dataset, 0,1,searchperiod, benefits_week30) %>%
  knitr::kable(booktabs=T) %>%
    kableExtra::kable_styling(font_size = 7, latex_options = "hold_position")
```


5. Assume that caseworkers only apply search periods to applicants who benefit from it. How does this affects the bounds.

If people only select into the treatment if it works (meaning, decreasing the probability of benefits), we have:

$$
\mathbb{E}[Y^*_1 | D=1] \leq \mathbb{E}[Y^*_0 | D = 1] \text{ and } \mathbb{E}[Y^*_0 | D = 0] \leq \mathbb{E}[Y^*_1 | D = 0]
$$
Since the case is the opposite of the case that is worked out on the lecture slides, we cannot blindly apply the formulate, but realizing that:

$$
y_{min} \leq \mathbb{E}[Y^*_1 | D=1] \leq \mathbb{E}[Y^*_0 | D = 1] \leq y_{max} \text{ and} \\
y_{min} \leq \mathbb{E}[Y^*_0 | D = 0] \leq \mathbb{E}[Y^*_1 | D = 0] \leq y_{max}
$$
We can evaluate $\mathbb{E}[Y^*_1]$, and we get:

$$
\mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + \text{Pr}[D=0] * \mathbb{E}[Y^*_0 | D=0] \leq \mathbb{E}[Y^*_1] \leq \mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + y_{max} * \text{Pr}[D=0]
$$
And for $\mathbb{E}[Y^*_0]$, we get:

$$
\mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] + \text{Pr}[D=1] * \mathbb{E}[Y^*_1 | D = 1] \leq \mathbb{E}[Y^*_0] \leq \mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] + \text{Pr}[D=1]*y_{max}
$$
Then, realizing that the lower bound of $\mathbb{E}[Y^*_1 - Y^*_0]$ is the lower bound of $\mathbb{E}[Y^*_1]$ minus the upper bound of $\mathbb{E}[Y^*_0]$, and _mutatis mutandis_ for the upper bound of $\mathbb{E}[Y^*_1 - Y^*_0]$, after rewriting, we find:

$$
-\text{Pr}(D=1) \cdot \left( y_{max} - \mathbb{E}[Y^*_1 | D = 1] \right) \leq \mathbb{E}[Y^*_1 - Y^*_0] \leq \text{Pr}(D=0) \cdot \left( y_{max} - \mathbb{E}[Y^*_0 | D = 0] \right)
$$

Which corresponds to the same properties as found in the lecture slides (i.e. narrower bounds, but without ever excluding zero). Implementing these bounds gives the following:

```{r, results='asis'}
bounds_info <- dataset %>%
  summarize(pr_treated = mean(searchperiod, na.rm = TRUE), 
            pr_untreated = 1 - pr_treated,
            y_max = 1)

expected_y_given_deq1 <- dataset %>%
    dplyr::filter(searchperiod == 1) %>%
             summarize(mean = mean(benefits_week10, na.rm = TRUE)) %>%
             pull()
  
expected_y_given_deq0 <- dataset%>%
    dplyr::filter(searchperiod == 0) %>%
             summarize(mean = mean(benefits_week10, na.rm = TRUE)) %>%
             pull()

lower_bound10 <- -bounds_info$pr_treated *(bounds_info$y_max - expected_y_given_deq1)
upper_bound10 <- bounds_info$pr_untreated * (bounds_info$y_max - expected_y_given_deq0)

paste('For the 10-weeks outcome, the lower bound for E$[Y^*_1 - Y^*_0]$ = ', lower_bound10)
paste('For the 10-weeks outcome, the upper bound for E$[Y^*_1 - Y^*_0]$= ', upper_bound10)


expected_y_given_deq1 <- dataset %>%
    dplyr::filter(searchperiod == 1) %>%
             summarize(mean = mean(benefits_week30, na.rm = TRUE)) %>%
             pull()
  
expected_y_given_deq0 <- dataset%>%
    dplyr::filter(searchperiod == 0) %>%
             summarize(mean = mean(benefits_week30, na.rm = TRUE)) %>%
             pull()

lower_bound30 <- -bounds_info$pr_treated *(bounds_info$y_max - expected_y_given_deq1)
upper_bound30 <- bounds_info$pr_untreated * (bounds_info$y_max - expected_y_given_deq0)

paste('For the 30-weeks outcome, the lower bound for E[Y^*_1 - Y^*_0] = ', lower_bound30)
paste('For the 30-weeks outcome, the upper bound for E[Y^*_1 - Y^*_0]= ', upper_bound30)
```

6. Next, imposed the monotone treatment response and the monotone treatment selection assumption separately and also jointly.

(i) First, we work out the case for our data, in which a favorable outcome is no benefits. Then, the MTS assumption becomes:

\begin{align*}
&y_{min} \leq \mathbb{E}[Y^*_1 | D = 1] \leq \mathbb{E}[Y^*_1 | D = 0 ] \leq y_{max} \\
&y_{min} \leq \mathbb{E}[Y^*_0 | D = 1] \leq \mathbb{E}[Y^*_0 | D = 0] \leq y_{max}
\end{align*}

This means that individuals who are or would have been assigned to the treatment group would have more favorable outcomes than non-treated subjects, whatever their treatment status. Bounding $\mathbb{E}[Y^*_1]$ gives: 

$$
\mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + \mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=0] \leq \mathbb{E}[Y^*_1] \leq \mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + y_{max} * \text{Pr}[D=0]
$$

And bounding $\mathbb{E}[Y^*_0]$ gives:
$$
\mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] + y_{min} * \text{Pr}[D=1] \leq \mathbb{E}[Y^*_0] \leq \mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] + \mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=1]
$$

Simplifying both bounds, and realizing that the lower bound for $\mathbb{E}[Y^*_1 - Y^*_0]$ equals the lower bound for $Y^*_1$ minus the upper bound for $Y^*_0$, and the upper bound for $\mathbb{E}[Y^*_1 - Y^*_0]$ equals the upper bound for $Y^*_1$ minus the lower bound for $Y^*_0$, we find that the MTS bounds are:*

\begin{multline}
\mathbb{E}[Y^*_1 | D=1] - \mathbb{E}[Y^*_0 | D = 0 ] \leq \mathbb{E}[Y^*_1 - Y^*_0] \leq \\
\text{Pr}[D=1] * \mathbb{E}[Y^*_1 | D =1] + \text{Pr}[D=0] * y_{max} - \text{Pr}[D=0] * \mathbb{E}[Y^*_0 | D = 0] - \text{Pr}[D=1] * y_{min}
\end{multline}

```{r, results='asis'}
pr_treated <- mean(dataset$searchperiod, na.rm = TRUE)
pr_untreated = 1 - pr_treated
y_max <- 1
y_min <- 0 

paste("The lower bound for $E[Y^*_1 - Y^*_0]$ is", expected_y_given_deq1 - expected_y_given_deq0)
paste("The upper bound for $E[Y^*_1 - Y^*_0]$ is", 
      pr_treated*expected_y_given_deq1 + 
        pr_untreated * y_max -
        pr_untreated * expected_y_given_deq0 -
        pr_treated * y_min)

```

After some rewriting, this result is a nice "mirror case" of the results on the slides, as it should be. 

(ii) Imposing the MTR means in our case: $y_{min} \leq Y^*_1 \leq Y^*_0 \leq y_{max}$. We then again proceed to analyse the bounds for $Y^*_1$ and $Y^*_0$:

$$
\mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + \text{Pr}[D=0] * y_{min} \leq \mathbb{E}[Y^*_1] \leq \mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] + \mathbb{E}[Y^*_0 | D = 0 ] * \text{Pr}[D=0]
$$

$$
\mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] + \mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1] \leq \mathbb{E}[Y^*_0] \leq \mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0]  + y_{max} * \text{Pr}[D=1]
$$

Then, applying the same procedure as before, we find that $\mathbb{E}[Y^*_1 - Y^*_0]$ is bounded as follows:

\begin{align*}
\mathbb{E}[Y^*_1 | D = 1] * \text{Pr}[D=1]  + \text{Pr}[D=0] * y_{min} \\
- \mathbb{E}[Y^*_0 | D = 0] * \text{Pr}[D=0] - \text{Pr}[D=1] * y_{max} \leq 
\mathbb{E}[Y^*_1 - Y^*_0] \leq 0
\end{align*}

We observe that we have again a mirror case compared to the lecture slides: the upper bound is now 0, instead of the lower bound.

(iii) Applying MTS and MTR together simply yields the most strict bounds from both sides. After some simplifying, we find that it reduces to:

$$
\mathbb{E}[Y^*_1 | D = 1] - \mathbb{E}[Y^*_0 | D = 0] \leq \mathbb{E}[Y^*_1 - Y^*_0] \leq 0
$$

7. Usually higher educated workers have more favorable labor market outcomes. Use education as monotone instrumental variable and compute the bounds.

In our case, the monotone instrumental variable assumption is that the higher the education, the lower on average the benefits, i.e.:

$$
\mathbb{E}[Y^*_d | Z = \text{BachelorMaster}] \leq \mathbb{E}[Y^*_d | Z = \text{Vocational}] \leq \text {Etc.}
$$

After repeating the way of thinking in the lecture slides, but omitting the algebraic "proof" for brevity, in comparison to the slides, the formula for the bounds on the expected potential outcomes, conditional on $Z$ changes to:

$$
\max_{z' \geq z} \{ LB(d,z) \} \leq  \mathbb{E}[Y^*_d | Z=z] \leq \min_{z' \leq z} \{ UB(d,z)\} 
$$
And unconditionally, to: 

$$
\sum_{z} \text{Pr}[Z=z] \max_{z' \geq z} LB(d, z') \leq \mathbb{E}[Y^*_d] \leq \sum_{z} \text{Pr}[Z=z] \max_{z'\leq z} UB(d,z')
$$

We now implement this in a function, after slightly modifying the data so that education is in one column, and we omit the "unknown" education from the dataset, because it is unclear where that fits in the monotonicity:

```{r}
dataset_new <- dataset %>%
  mutate(education = dplyr::case_when(educ_bachelormaster == 1 ~ 4,
                                      educ_vocational == 1 ~ 3,
                                      educ_prepvocational == 1 ~ 2,
                                      educ_primaryorless == 1 ~ 1)) %>%
  filter(!is.na(education))

```

First, we conduct the analysis for the 10-weeks outcome: 

```{r}

# We start with calculating the original lower and upper bounds using the previous function
# no_assumption_bounds for each group separately
original_bounds <- dataset_new %>%
  group_split(education) %>%
  map_df(~ no_assumption_bounds(.x, 0, 1, searchperiod, benefits_week10)) %>%
  mutate(z = c(1,2,3,4))

# Write an empty data frame to which we will write the effective LBs and UBs
effective_bounds <- data.frame(z = rep(c(1,2,3,4),2),
                               effective_lb = rep(0,8),  
                               effective_ub = rep(0,8),
                               d = c(rep(0,4), rep(1,4))) %>%
  arrange(z)
 # Then, we for each Z and d, we find the "maximum" and "minimum" bounds among the feasible z'
for(i in 1:4){
  
  # Find the maximum lower bound y0 and write them to the effective bounds df
  effective_bounds[2*i-1, "effective_lb"] <- original_bounds %>%
    filter(z >= i) %>%
    summarize(effective_lb = max(lower_bound_y0)) %>% pull()
  
  # Find the maximum lower bound y1 and write them to the effective bounds df
  effective_bounds[2*i, "effective_lb"] <- original_bounds %>%
    filter(z >= i) %>%
    summarize(effective_lb = max(lower_bound_y1)) %>% pull()
  
  # Find the minimum upper bound y0 ..
  effective_bounds[2*i-1, "effective_ub"] <- original_bounds %>%
    filter(z <= i) %>%
    summarize(effective_ub = min(upper_bound_y0)) %>% pull()
  
  # Find the minimum upper bound y1
  effective_bounds[2*i, "effective_ub"] <- original_bounds %>%
    filter(z <= i) %>%
    summarize(effective_ub = min(upper_bound_y1)) %>% pull()
  
}
```

```{r}
# Then, we weight average the "effective" bounds to arrive at the bounds for Y^*_1 and Y^*_0
## First, calculate the probabilities
probs <- dataset_new %>%
  group_by(education) %>% 
  summarize(n = n()) %>%
  mutate(freq = n/sum(n)) %>% pull()

## Lower Bound Y_0:
lb_y0 <- effective_bounds %>%
  filter(d == 0) %>%
  select(effective_lb) %>% pull()

## Upper Bound Y_0:
ub_y0 <- effective_bounds %>%
  filter(d == 0) %>%
  select(effective_ub) %>% pull()

## Lower Bound Y_1:
lb_y1 <- effective_bounds %>%
  filter(d == 1) %>%  
  select(effective_lb) %>% pull()

## Upper Bound Y_1:
ub_y1 <- effective_bounds %>%
  filter(d == 1) %>%  
  select(effective_ub) %>% pull()

## Summarize in data.frame
data.frame(lower_bound_y0 = sum(probs*lb_y0), upper_bound_y0 = sum(probs*ub_y0),
           lower_bound_y1 = sum(probs*lb_y1), upper_bound_y1 = sum(probs*ub_y1)) %>%
  mutate(lower_bound_ate = lower_bound_y1 - upper_bound_y0,
         upper_bound_ate = upper_bound_y1 - lower_bound_y0) %>%
  knitr::kable(booktabs=T) %>%
  kableExtra::kable_styling(font_size = 7, latex_options = "hold_position")
```


We repeate the above exercise again for the 30-weeks outcome:


```{r}

# We start with calculating the original lower and upper bounds using the previous function
# no_assumption_bounds for each group separately
original_bounds <- dataset_new %>%
  group_split(education) %>%
  map_df(~ no_assumption_bounds(.x, 0, 1, searchperiod, benefits_week30)) %>%
  mutate(z = c(1,2,3,4))

# Write an empty data frame to which we will write the effective LBs and UBs
effective_bounds <- data.frame(z = rep(c(1,2,3,4),2),
                               effective_lb = rep(0,8),  
                               effective_ub = rep(0,8),
                               d = c(rep(0,4), rep(1,4))) %>%
  arrange(z)
 # Then, we for each Z and d, we find the "maximum" and "minimum" bounds among the feasible z'
for(i in 1:4){
  
  # Find the maximum lower bound y0 and write them to the effective bounds df
  effective_bounds[2*i-1, "effective_lb"] <- original_bounds %>%
    filter(z >= i) %>%
    summarize(effective_lb = max(lower_bound_y0)) %>% pull()
  
  # Find the maximum lower bound y1 and write them to the effective bounds df
  effective_bounds[2*i, "effective_lb"] <- original_bounds %>%
    filter(z >= i) %>%
    summarize(effective_lb = max(lower_bound_y1)) %>% pull()
  
  # Find the minimum upper bound y0 ..
  effective_bounds[2*i-1, "effective_ub"] <- original_bounds %>%
    filter(z <= i) %>%
    summarize(effective_ub = min(upper_bound_y0)) %>% pull()
  
  # Find the minimum upper bound y1
  effective_bounds[2*i, "effective_ub"] <- original_bounds %>%
    filter(z <= i) %>%
    summarize(effective_ub = min(upper_bound_y1)) %>% pull()
  
}
```

```{r}
# Then, we weight average the "effective" bounds to arrive at the bounds for Y^*_1 and Y^*_0
## First, calculate the probabilities
probs <- dataset_new %>%
  group_by(education) %>% 
  summarize(n = n()) %>%
  mutate(freq = n/sum(n)) %>% pull()

## Lower Bound Y_0:
lb_y0 <- effective_bounds %>%
  filter(d == 0) %>%
  select(effective_lb) %>% pull()

## Upper Bound Y_0:
ub_y0 <- effective_bounds %>%
  filter(d == 0) %>%
  select(effective_ub) %>% pull()

## Lower Bound Y_1:
lb_y1 <- effective_bounds %>%
  filter(d == 1) %>%  
  select(effective_lb) %>% pull()

## Upper Bound Y_1:
ub_y1 <- effective_bounds %>%
  filter(d == 1) %>%  
  select(effective_ub) %>% pull()

## Summarize in data.frame
data.frame(lower_bound_y0 = sum(probs*lb_y0), upper_bound_y0 = sum(probs*ub_y0),
           lower_bound_y1 = sum(probs*lb_y1), upper_bound_y1 = sum(probs*ub_y1)) %>%
  mutate(lower_bound_ate = lower_bound_y1 - upper_bound_y0,
         upper_bound_ate = upper_bound_y1 - lower_bound_y0) %>%
  knitr::kable(booktabs=T) %>%
  kableExtra::kable_styling(font_size = 7, latex_options = "hold_position")
```